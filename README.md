# AI & Computer Visionâ€“Enhanced Classroom Observation Tool (COPUS-Style)

This repository contains a **research-grade, privacy-aware classroom observation system** that uses **computer vision and AI** to analyze classroom videos and generate **COPUS-style instructional and student engagement codes** at **2â€‘minute intervals**.

The tool is designed to support **STEM education research**, **faculty professional development**, and **equity-focused classroom analytics**, while maintaining **transparency and privacy by design**.

---

## ğŸš€ Key Features

- ğŸ¥ **Video-based classroom observation**
- ğŸ§  **AI-powered analysis** using YOLOv8 + multi-object tracking
- ğŸ§‘â€ğŸ« Automatic **instructor vs. student role inference**
- ğŸ“Š **COPUS-style codes** aggregated per **2-minute interval**
- ğŸ”’ **Face blurring enabled by default** for privacy protection
- ğŸ“ **Dashboard-ready outputs**:
  - CSV (analysis-friendly)
  - JSON (web dashboard / visualization-ready)
- ğŸ“ˆ **Automated plots** for classroom dynamics and engagement trends
- ğŸ§© Modular, transparent heuristics (easy to replace with trained models)

---

## ğŸ§  COPUS-Style Outputs

The system generates **proxy COPUS-style codes** based on observable visual signals such as motion, spatial clustering, and instructor dominance.

### Instructor Codes (subset)
- `Lec` â€“ Lecturing
- `FUp` â€“ Follow-up / feedback
- `MG` â€“ Moving & guiding
- `Adm` â€“ Administration / transitions
- `Unk` â€“ Uncertain / mixed

### Student Codes (subset)
- `Lis` â€“ Listening
- `Grp` â€“ Group work
- `Ind` â€“ Individual work
- `AsQ` â€“ Asking questions
- `Unk` â€“ Uncertain / mixed

> âš ï¸ **Important:**  
> COPUS is traditionally human-coded. This tool provides **transparent, AI-based proxy codes**. For publication-grade validity, calibrate against human COPUS annotations and report agreement metrics (e.g., Cohenâ€™s Îº, macroâ€‘F1).

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ Classroom_Observation_COPUS.ipynb   # Main research-grade Jupyter notebook
â”œâ”€â”€ outputs_copus/
â”‚   â”œâ”€â”€ annotated_blurred.mp4           # Annotated + face-blurred video
â”‚   â”œâ”€â”€ copus_intervals.csv              # Interval-level COPUS-style codes
â”‚   â”œâ”€â”€ copus_intervals.json             # Dashboard-ready JSON
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ signals_over_time.png
â”‚       â”œâ”€â”€ lecture_vs_groupwork.png
â”‚       â”œâ”€â”€ instructor_code_frequency.png
â”‚       â””â”€â”€ student_code_frequency.png
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### Requirements
- Python 3.9+
- Recommended: GPU for faster inference

### Install dependencies
```bash
pip install ultralytics opencv-python pandas numpy matplotlib
```

YOLOv8 weights will be downloaded automatically on first run.

---

## â–¶ï¸ How to Run

1. Place your classroom video (e.g., `classroom.mp4`) in the project directory.
2. Open the notebook:
```bash
jupyter notebook Classroom_Observation_COPUS.ipynb
```
3. Set the video path in the configuration cell:
```python
VIDEO_PATH = "classroom.mp4"
```
4. Run all cells.

Outputs will be saved automatically to `outputs_copus/`.

---

## ğŸ” Privacy & Ethics

This project is built with **Trustworthy AI principles**:

- âœ… **Face blurring enabled by default**
- âœ… No identity recognition or biometric storage
- âœ… Aggregated, interval-level outputs only
- âœ… Designed for IRB-compliant educational research

For real deployments, consider:
- On-device processing
- Access control for raw videos
- Exporting only aggregated statistics

---

## ğŸ“Š Dashboard Integration

The exported `copus_intervals.json` is structured for direct use in:
- React dashboards
- Streamlit apps
- Plotly Dash
- Tableau / PowerBI (via JSON import)

Each interval contains:
- Time bounds
- Engagement metrics
- Instructor COPUS-style codes
- Student COPUS-style codes

---

## ğŸ”¬ Research Extensions (Future Work)

- Train temporal models (TCN / Transformer) on labeled COPUS data
- Add speech/activity fusion (audio + vision)
- Report inter-rater agreement vs. human coders
- Extend to DEI-focused participation analysis
- Real-time classroom feedback systems

---

## ğŸ“œ Citation

If you use this work in academic research, please cite:

```
Adeika, B. (2025).
AI and Computer Visionâ€“Enhanced Classroom Observation Tool for COPUS-Style Analysis.
GitHub repository.
```

---

## ğŸ¤ License

This project is released for **research and educational use**.  
Commercial use may require additional permissions.

---

## âœ¨ Author

**Blessing Adeika**  
PhD Researcher â€” Trustworthy AI & Computer Vision  
Morgan State University

---

If youâ€™d like help adding:
- a **demo dashboard**
- a **methods section for a paper**
- or **EB2/EB1-ready project descriptions**

just say the word.
