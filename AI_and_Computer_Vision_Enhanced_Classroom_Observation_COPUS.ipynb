{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c10aaf5c",
      "metadata": {
        "id": "c10aaf5c"
      },
      "source": [
        "# Classroom Observation (COPUS‑Style, 2‑Minute Intervals)\n",
        "This notebook runs a **privacy‑aware** classroom observation pipeline on a classroom video:\n",
        "\n",
        "- **Person detection + tracking** (YOLOv8 + ByteTrack via `ultralytics`)\n",
        "- **Face blurring by default** (OpenCV Haar cascade)\n",
        "- **COPUS‑style codes** aggregated **per 2‑minute interval** (heuristic baseline; replaceable with trained classifiers)\n",
        "- Exports **dashboard‑ready JSON** and **CSV**\n",
        "- Generates **plots** for quick analysis\n",
        "\n",
        "⚠️ **Important:** COPUS is typically human‑coded. This notebook produces **COPUS‑style proxy codes** based on measurable visual cues (movement, clustering, instructor dominance). For publication‑grade validity, calibrate with labeled COPUS data and report inter‑rater / model agreement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb8b338",
      "metadata": {
        "id": "7eb8b338"
      },
      "outputs": [],
      "source": [
        "# If needed, install dependencies (run once)\n",
        "# !pip -q install ultralytics opencv-python pandas numpy matplotlib\n",
        "\n",
        "import os, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9602b18a",
      "metadata": {
        "id": "9602b18a"
      },
      "source": [
        "## 1) Configuration\n",
        "Set your video path and output directory below. The pipeline will produce:\n",
        "- `annotated_blurred.mp4`\n",
        "- `copus_intervals.csv`\n",
        "- `copus_intervals.json`\n",
        "- plots saved in `plots/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008be43a",
      "metadata": {
        "id": "008be43a"
      },
      "outputs": [],
      "source": [
        "# === USER SETTINGS ===\n",
        "VIDEO_PATH = \"classroom.mp4\"   # <-- change this to your classroom video file\n",
        "OUT_DIR = \"outputs_copus\"\n",
        "\n",
        "# Analysis settings\n",
        "INTERVAL_SEC = 120            # COPUS convention: 2-minute intervals\n",
        "WINDOW_SEC = 5                # short window for smoothing\n",
        "CONF_THRES = 0.35             # YOLO confidence\n",
        "MAX_DET = 60                  # max detections per frame\n",
        "MODEL_WEIGHTS = \"yolov8n.pt\"  # switch to \"yolov8s.pt\" for improved accuracy (slower)\n",
        "\n",
        "# Privacy settings\n",
        "BLUR_FACES = True\n",
        "FACE_BLUR_KERNEL = (31, 31)   # larger => stronger blur\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print(\"Output directory:\", os.path.abspath(OUT_DIR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26692310",
      "metadata": {
        "id": "26692310"
      },
      "source": [
        "## 2) Helper functions (tracking, privacy blurring, COPUS-style coding)\n",
        "These heuristics are designed to be **transparent** and easy to replace with trained models later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a63538",
      "metadata": {
        "id": "64a63538"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TrackState:\n",
        "    last_center: Tuple[float, float]\n",
        "    ema_speed: float = 0.0  # exponential moving average of pixel speed\n",
        "\n",
        "\n",
        "def pick_instructor(person_boxes: List[Tuple[float, float, float, float]], frame_w: int, frame_h: int):\n",
        "    \"\"\"Heuristic: instructor tends to be near the 'front' (top of frame) and/or larger.\"\"\"\n",
        "    if not person_boxes:\n",
        "        return None, -1\n",
        "\n",
        "    scores = []\n",
        "    for b in person_boxes:\n",
        "        x1, y1, x2, y2 = b\n",
        "        area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        frontness = 1.0 - (y2 / (frame_h + 1e-9))  # higher if nearer top\n",
        "        s = 0.6 * (area / (frame_w * frame_h + 1e-9)) + 0.4 * frontness\n",
        "        scores.append(s)\n",
        "\n",
        "    idx = int(np.argmax(scores))\n",
        "    return person_boxes[idx], idx\n",
        "\n",
        "\n",
        "def cluster_score(centers: np.ndarray, eps_px: float = 90.0) -> float:\n",
        "    \"\"\"Grouping proxy: closer nearest-neighbor distances => higher group-work likelihood.\"\"\"\n",
        "    if len(centers) < 2:\n",
        "        return 0.0\n",
        "    dists = []\n",
        "    for i in range(len(centers)):\n",
        "        diffs = centers - centers[i]\n",
        "        dd = np.sqrt((diffs[:, 0] ** 2 + diffs[:, 1] ** 2) + 1e-9)\n",
        "        dd_sorted = np.sort(dd)\n",
        "        dists.append(dd_sorted[1])  # nearest neighbor (excluding self)\n",
        "    nn = float(np.mean(dists))\n",
        "    return float(np.clip((eps_px - nn) / eps_px, 0.0, 1.0))\n",
        "\n",
        "\n",
        "def init_face_detector():\n",
        "    \"\"\"OpenCV Haar cascade face detector (fast baseline).\"\"\"\n",
        "    cascade_path = os.path.join(cv2.data.haarcascades, \"haarcascade_frontalface_default.xml\")\n",
        "    if not os.path.exists(cascade_path):\n",
        "        raise FileNotFoundError(f\"Could not find Haar cascade at: {cascade_path}\")\n",
        "    return cv2.CascadeClassifier(cascade_path)\n",
        "\n",
        "\n",
        "def blur_faces_in_frame(frame_bgr: np.ndarray, face_cascade, blur_kernel=(31, 31)) -> np.ndarray:\n",
        "    \"\"\"Detects faces and blurs them. This is a baseline privacy step.\"\"\"\n",
        "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    # scaleFactor/minNeighbors tuned for classroom-ish videos; adjust if needed\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    out = frame_bgr.copy()\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi = out[y:y+h, x:x+w]\n",
        "        if roi.size == 0:\n",
        "            continue\n",
        "        roi_blur = cv2.GaussianBlur(roi, blur_kernel, 0)\n",
        "        out[y:y+h, x:x+w] = roi_blur\n",
        "    return out\n",
        "\n",
        "\n",
        "def copus_style_codes_from_signals(\n",
        "    people_count: float,\n",
        "    instructor_move: float,\n",
        "    student_move: float,\n",
        "    grouping: float,\n",
        "    lecture_score: float,\n",
        "    groupwork_score: float\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"Map signals -> COPUS-style code sets (proxy).\n",
        "\n",
        "    Instructor COPUS-style codes (subset):\n",
        "      - 'Lec'   (Lecturing)\n",
        "      - 'FUp'   (Follow-up / feedback; proxy via moderate instructor movement with low student movement)\n",
        "      - 'MG'    (Moving & guiding; proxy via high instructor movement + moderate student movement)\n",
        "      - 'Adm'   (Administration/management; proxy via low overall motion)\n",
        "      - '1o1'   (One-on-one; proxy via low people_count + localized clusters; rough)\n",
        "\n",
        "    Student COPUS-style codes (subset):\n",
        "      - 'Lis'   (Listening)\n",
        "      - 'Ind'   (Individual thinking/working; proxy via low movement + low clustering)\n",
        "      - 'Grp'   (Group work)\n",
        "      - 'AsQ'   (Asking questions; proxy via moderate student movement spikes; very rough)\n",
        "\n",
        "    Note: This is *not* a validated COPUS coder. It is a transparent baseline.\n",
        "    \"\"\"\n",
        "    I, S = [], []\n",
        "\n",
        "    # Instructor codes\n",
        "    if lecture_score >= 0.55 and student_move <= 10:\n",
        "        I.append(\"Lec\")\n",
        "    if 0.35 <= lecture_score < 0.55 and student_move <= 12:\n",
        "        I.append(\"FUp\")\n",
        "    if instructor_move >= 18 and student_move >= 8:\n",
        "        I.append(\"MG\")  # moving & guiding\n",
        "    if instructor_move < 8 and student_move < 6:\n",
        "        I.append(\"Adm\")  # low activity / transitions / admin\n",
        "\n",
        "    # Student codes\n",
        "    if groupwork_score >= 0.60 and grouping >= 0.40:\n",
        "        S.append(\"Grp\")\n",
        "    if lecture_score >= 0.50 and student_move < 10:\n",
        "        S.append(\"Lis\")\n",
        "    if student_move < 8 and grouping < 0.25 and lecture_score < 0.55:\n",
        "        S.append(\"Ind\")\n",
        "    if 10 <= student_move <= 16 and lecture_score < 0.55:\n",
        "        S.append(\"AsQ\")  # weak proxy\n",
        "\n",
        "    # Ensure at least one code each (helps dashboards)\n",
        "    if not I:\n",
        "        I = [\"Unk\"]\n",
        "    if not S:\n",
        "        S = [\"Unk\"]\n",
        "\n",
        "    return {\"instructor_codes\": sorted(list(set(I))), \"student_codes\": sorted(list(set(S)))}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d76d3ae",
      "metadata": {
        "id": "5d76d3ae"
      },
      "source": [
        "## 3) Core analyzer\n",
        "This function processes the video, applies face blurring, tracks people, computes signals, aggregates **2‑minute COPUS‑style intervals**, and exports artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8bd249b",
      "metadata": {
        "id": "a8bd249b"
      },
      "outputs": [],
      "source": [
        "def analyze_classroom_video(\n",
        "    video_path: str,\n",
        "    out_dir: str,\n",
        "    interval_sec: int = 120,\n",
        "    window_sec: int = 5,\n",
        "    conf_thres: float = 0.35,\n",
        "    max_det: int = 60,\n",
        "    model_weights: str = \"yolov8n.pt\",\n",
        "    blur_faces: bool = True,\n",
        "    face_blur_kernel=(31, 31),\n",
        ") -> Dict[str, str]:\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    plots_dir = os.path.join(out_dir, \"plots\")\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Could not open video: {video_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
        "\n",
        "    annotated_path = os.path.join(out_dir, \"annotated_blurred.mp4\")\n",
        "    csv_path = os.path.join(out_dir, \"copus_intervals.csv\")\n",
        "    json_path = os.path.join(out_dir, \"copus_intervals.json\")\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(annotated_path, fourcc, fps, (W, H))\n",
        "\n",
        "    model = YOLO(model_weights)\n",
        "\n",
        "    face_cascade = init_face_detector() if blur_faces else None\n",
        "\n",
        "    # tracking/motion\n",
        "    track_state: Dict[int, TrackState] = {}\n",
        "\n",
        "    window_frames = max(1, int(window_sec * fps))\n",
        "    interval_frames = max(1, int(interval_sec * fps))\n",
        "\n",
        "    # collect per-window signals then aggregate into 2-minute intervals\n",
        "    cur_interval = {\n",
        "        \"people_count\": [],\n",
        "        \"student_move\": [],\n",
        "        \"instructor_move\": [],\n",
        "        \"grouping\": [],\n",
        "        \"lecture_score\": [],\n",
        "        \"groupwork_score\": [],\n",
        "    }\n",
        "\n",
        "    intervals = []\n",
        "    frame_idx = 0\n",
        "\n",
        "    def finalize_interval(start_frame: int, end_frame: int):\n",
        "        if len(cur_interval[\"people_count\"]) == 0:\n",
        "            return None\n",
        "\n",
        "        t_start = start_frame / fps\n",
        "        t_end = end_frame / fps\n",
        "\n",
        "        # averages\n",
        "        people_avg = float(np.mean(cur_interval[\"people_count\"]))\n",
        "        stud_move_avg = float(np.mean(cur_interval[\"student_move\"]))\n",
        "        instr_move_avg = float(np.mean(cur_interval[\"instructor_move\"]))\n",
        "        grouping_avg = float(np.mean(cur_interval[\"grouping\"]))\n",
        "        lecture_avg = float(np.mean(cur_interval[\"lecture_score\"]))\n",
        "        groupwork_avg = float(np.mean(cur_interval[\"groupwork_score\"]))\n",
        "\n",
        "        codes = copus_style_codes_from_signals(\n",
        "            people_count=people_avg,\n",
        "            instructor_move=instr_move_avg,\n",
        "            student_move=stud_move_avg,\n",
        "            grouping=grouping_avg,\n",
        "            lecture_score=lecture_avg,\n",
        "            groupwork_score=groupwork_avg\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            \"interval_index\": len(intervals),\n",
        "            \"t_start_sec\": round(t_start, 3),\n",
        "            \"t_end_sec\": round(t_end, 3),\n",
        "            \"people_avg\": round(people_avg, 3),\n",
        "            \"student_movement_avg\": round(stud_move_avg, 3),\n",
        "            \"instructor_movement_avg\": round(instr_move_avg, 3),\n",
        "            \"cluster_score_avg\": round(grouping_avg, 3),\n",
        "            \"lecture_score_avg\": round(lecture_avg, 3),\n",
        "            \"groupwork_score_avg\": round(groupwork_avg, 3),\n",
        "            \"instructor_codes\": \",\".join(codes[\"instructor_codes\"]),\n",
        "            \"student_codes\": \",\".join(codes[\"student_codes\"]),\n",
        "        }\n",
        "        return row\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        # privacy first: blur faces in the working frame (and consequently in annotated export)\n",
        "        if blur_faces and face_cascade is not None:\n",
        "            frame_proc = blur_faces_in_frame(frame, face_cascade, blur_kernel=face_blur_kernel)\n",
        "        else:\n",
        "            frame_proc = frame\n",
        "\n",
        "        # YOLO person tracking\n",
        "        results = model.track(\n",
        "            source=frame_proc,\n",
        "            persist=True,\n",
        "            conf=conf_thres,\n",
        "            iou=0.5,\n",
        "            classes=[0],  # person only\n",
        "            max_det=max_det,\n",
        "            verbose=False,\n",
        "        )\n",
        "        r = results[0]\n",
        "\n",
        "        boxes_xyxy, track_ids = [], []\n",
        "        if r.boxes is not None and len(r.boxes) > 0:\n",
        "            b = r.boxes.xyxy.cpu().numpy()\n",
        "            tid = r.boxes.id.cpu().numpy() if r.boxes.id is not None else None\n",
        "            boxes_xyxy = [tuple(map(float, bb)) for bb in b]\n",
        "            track_ids = [int(x) for x in tid] if tid is not None else list(range(len(boxes_xyxy)))\n",
        "\n",
        "        instructor_box, instructor_idx = pick_instructor(boxes_xyxy, W, H)\n",
        "\n",
        "        # movement estimation (EMA of pixel speed per track)\n",
        "        centers = []\n",
        "        movement_by_id = {}\n",
        "        for bb, tid in zip(boxes_xyxy, track_ids):\n",
        "            x1, y1, x2, y2 = bb\n",
        "            cx, cy = (x1 + x2) / 2.0, (y1 + y2) / 2.0\n",
        "            centers.append((cx, cy))\n",
        "\n",
        "            if tid not in track_state:\n",
        "                track_state[tid] = TrackState(last_center=(cx, cy), ema_speed=0.0)\n",
        "            else:\n",
        "                lx, ly = track_state[tid].last_center\n",
        "                speed = float(np.sqrt((cx - lx) ** 2 + (cy - ly) ** 2))\n",
        "                track_state[tid].ema_speed = 0.7 * track_state[tid].ema_speed + 0.3 * speed\n",
        "                track_state[tid].last_center = (cx, cy)\n",
        "\n",
        "            movement_by_id[tid] = track_state[tid].ema_speed\n",
        "\n",
        "        centers_np = np.array(centers, dtype=np.float32) if centers else np.zeros((0, 2), dtype=np.float32)\n",
        "\n",
        "        people_count = len(boxes_xyxy)\n",
        "        instructor_move = 0.0\n",
        "        student_moves = []\n",
        "\n",
        "        for i, tid in enumerate(track_ids):\n",
        "            m = movement_by_id.get(tid, 0.0)\n",
        "            if instructor_box is not None and i == instructor_idx:\n",
        "                instructor_move = m\n",
        "            else:\n",
        "                student_moves.append(m)\n",
        "\n",
        "        student_move = float(np.mean(student_moves)) if student_moves else 0.0\n",
        "        grouping = cluster_score(centers_np, eps_px=90.0)\n",
        "\n",
        "        # Transparent \"scores\" for dashboards\n",
        "        lecture_score = float(np.clip((instructor_move / 30.0) - (student_move / 40.0) + 0.25, 0.0, 1.0))\n",
        "        groupwork_score = float(np.clip((student_move / 35.0) + 0.75 * grouping, 0.0, 1.0))\n",
        "\n",
        "        # record per-window\n",
        "        cur_interval[\"people_count\"].append(people_count)\n",
        "        cur_interval[\"student_move\"].append(student_move)\n",
        "        cur_interval[\"instructor_move\"].append(instructor_move)\n",
        "        cur_interval[\"grouping\"].append(grouping)\n",
        "        cur_interval[\"lecture_score\"].append(lecture_score)\n",
        "        cur_interval[\"groupwork_score\"].append(groupwork_score)\n",
        "\n",
        "        # Annotate frame (boxes only; faces are already blurred)\n",
        "        vis = frame_proc.copy()\n",
        "        for i, (bb, tid) in enumerate(zip(boxes_xyxy, track_ids)):\n",
        "            x1, y1, x2, y2 = map(int, bb)\n",
        "            is_instructor = (instructor_box is not None and i == instructor_idx)\n",
        "            label = f\"{'Instructor' if is_instructor else 'Student'} ID:{tid} v:{movement_by_id.get(tid, 0.0):.1f}\"\n",
        "            cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0) if is_instructor else (255, 255, 255), 2)\n",
        "            cv2.putText(vis, label, (x1, max(20, y1 - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 3)\n",
        "            cv2.putText(vis, label, (x1, max(20, y1 - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "        header = (\n",
        "            f\"COPUS-style interval:{len(intervals)} | people:{people_count} \"            f\"| lec:{lecture_score:.2f} grp:{groupwork_score:.2f} | cluster:{grouping:.2f}\"\n",
        "        )\n",
        "        cv2.putText(vis, header, (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 4)\n",
        "        cv2.putText(vis, header, (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
        "\n",
        "        writer.write(vis)\n",
        "\n",
        "        # finalize interval every interval_frames\n",
        "        if (frame_idx + 1) % interval_frames == 0:\n",
        "            start_frame = frame_idx + 1 - interval_frames\n",
        "            end_frame = frame_idx + 1\n",
        "            row = finalize_interval(start_frame, end_frame)\n",
        "            if row is not None:\n",
        "                intervals.append(row)\n",
        "            # reset\n",
        "            for k in cur_interval:\n",
        "                cur_interval[k] = []\n",
        "\n",
        "        frame_idx += 1\n",
        "        if total_frames and frame_idx % int(max(1, fps * 10)) == 0:\n",
        "            print(f\"Processed {frame_idx}/{total_frames} frames...\" հաստատ=True)\n",
        "\n",
        "    # finalize tail interval if remaining\n",
        "    if len(cur_interval[\"people_count\"]) > 0:\n",
        "        # last partial interval\n",
        "        start_frame = frame_idx - len(cur_interval[\"people_count\"])\n",
        "        end_frame = frame_idx\n",
        "        row = finalize_interval(start_frame, end_frame)\n",
        "        if row is not None:\n",
        "            intervals.append(row)\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "\n",
        "    df = pd.DataFrame(intervals)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    dashboard = {\n",
        "        \"schema_version\": \"1.0\",\n",
        "        \"video\": {\n",
        "            \"path\": os.path.abspath(video_path),\n",
        "            \"fps\": float(fps),\n",
        "            \"width\": int(W),\n",
        "            \"height\": int(H),\n",
        "            \"total_frames\": int(total_frames),\n",
        "        },\n",
        "        \"settings\": {\n",
        "            \"interval_sec\": int(interval_sec),\n",
        "            \"window_sec\": float(window_sec),\n",
        "            \"conf_thres\": float(conf_thres),\n",
        "            \"max_det\": int(max_det),\n",
        "            \"model_weights\": model_weights,\n",
        "            \"blur_faces\": bool(blur_faces),\n",
        "            \"face_blur_kernel\": list(face_blur_kernel),\n",
        "        },\n",
        "        \"intervals\": intervals,\n",
        "    }\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(dashboard, f, indent=2)\n",
        "\n",
        "    # ---- Plots (matplotlib; no custom colors specified) ----\n",
        "    if len(df) > 0:\n",
        "        t_mid = (df[\"t_start_sec\"].values + df[\"t_end_sec\"].values) / 2.0 / 60.0  # minutes\n",
        "\n",
        "        # Plot 1: People and motion\n",
        "        plt.figure()\n",
        "        plt.plot(t_mid, df[\"people_avg\"].values, label=\"People avg\")\n",
        "        plt.plot(t_mid, df[\"student_movement_avg\"].values, label=\"Student movement avg\")\n",
        "        plt.plot(t_mid, df[\"instructor_movement_avg\"].values, label=\"Instructor movement avg\")\n",
        "        plt.xlabel(\"Time (minutes)\")\n",
        "        plt.ylabel(\"Value\")\n",
        "        plt.title(\"Classroom signals over time (2-minute intervals)\")\n",
        "        plt.legend()\n",
        "        p1 = os.path.join(plots_dir, \"signals_over_time.png\")\n",
        "        plt.savefig(p1, dpi=200, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot 2: Lecture vs Groupwork score\n",
        "        plt.figure()\n",
        "        plt.plot(t_mid, df[\"lecture_score_avg\"].values, label=\"Lecture score\")\n",
        "        plt.plot(t_mid, df[\"groupwork_score_avg\"].values, label=\"Groupwork score\")\n",
        "        plt.xlabel(\"Time (minutes)\")\n",
        "        plt.ylabel(\"Score (0-1)\")\n",
        "        plt.title(\"Lecture vs Groupwork scores (2-minute intervals)\")\n",
        "        plt.legend()\n",
        "        p2 = os.path.join(plots_dir, \"lecture_vs_groupwork.png\")\n",
        "        plt.savefig(p2, dpi=200, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot 3: COPUS-style code counts\n",
        "        def explode_codes(col: str) -> pd.Series:\n",
        "            codes = []\n",
        "            for s in df[col].fillna(\"\"):\n",
        "                parts = [p.strip() for p in str(s).split(\",\") if p.strip()]\n",
        "                codes.extend(parts)\n",
        "            return pd.Series(codes)\n",
        "\n",
        "        instr_codes = explode_codes(\"instructor_codes\")\n",
        "        stud_codes = explode_codes(\"student_codes\")\n",
        "\n",
        "        instr_counts = instr_codes.value_counts().sort_index()\n",
        "        stud_counts = stud_codes.value_counts().sort_index()\n",
        "\n",
        "        plt.figure()\n",
        "        instr_counts.plot(kind=\"bar\")\n",
        "        plt.xlabel(\"Instructor code\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.title(\"Instructor COPUS-style code frequency\")\n",
        "        p3 = os.path.join(plots_dir, \"instructor_code_frequency.png\")\n",
        "        plt.savefig(p3, dpi=200, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure()\n",
        "        stud_counts.plot(kind=\"bar\")\n",
        "        plt.xlabel(\"Student code\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.title(\"Student COPUS-style code frequency\")\n",
        "        p4 = os.path.join(plots_dir, \"student_code_frequency.png\")\n",
        "        plt.savefig(p4, dpi=200, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "    return {\n",
        "        \"annotated_video\": annotated_path,\n",
        "        \"csv\": csv_path,\n",
        "        \"json\": json_path,\n",
        "        \"plots_dir\": plots_dir,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5185fcae",
      "metadata": {
        "id": "5185fcae"
      },
      "source": [
        "## 4) Run the analysis\n",
        "Run this cell after setting `VIDEO_PATH`. If your video is large, start with a short clip first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d9f2ed",
      "metadata": {
        "id": "a2d9f2ed"
      },
      "outputs": [],
      "source": [
        "artifacts = analyze_classroom_video(\n",
        "    video_path=VIDEO_PATH,\n",
        "    out_dir=OUT_DIR,\n",
        "    interval_sec=INTERVAL_SEC,\n",
        "    window_sec=WINDOW_SEC,\n",
        "    conf_thres=CONF_THRES,\n",
        "    max_det=MAX_DET,\n",
        "    model_weights=MODEL_WEIGHTS,\n",
        "    blur_faces=BLUR_FACES,\n",
        "    face_blur_kernel=FACE_BLUR_KERNEL,\n",
        ")\n",
        "\n",
        "artifacts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86e1724",
      "metadata": {
        "id": "f86e1724"
      },
      "source": [
        "## 5) Load exports (CSV/JSON) for dashboard use\n",
        "- The CSV is convenient for spreadsheets.\n",
        "- The JSON is ready for a web dashboard (e.g., React, Streamlit, or Plotly Dash)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dce79b5",
      "metadata": {
        "id": "8dce79b5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(artifacts[\"csv\"])\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a720253a",
      "metadata": {
        "id": "a720253a"
      },
      "outputs": [],
      "source": [
        "with open(artifacts[\"json\"], \"r\") as f:\n",
        "    dashboard = json.load(f)\n",
        "\n",
        "# Show JSON keys + first interval\n",
        "list(dashboard.keys()), dashboard[\"intervals\"][0] if dashboard[\"intervals\"] else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b174fa5e",
      "metadata": {
        "id": "b174fa5e"
      },
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}